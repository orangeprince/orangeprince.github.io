---
layout: post
title: "闲话SVM(一)"
category: "技术"
tags: [机器学习,SVM]
---

SVM，全称Support Vector Machines，中文叫做支持向量机，是最常用的机器学习算法之一。SVM的出现对机器学习的理论发展具有里程碑式的意义。而与此同时，SVM又是一个非常接地气的算法，模型的训练过程并不算复杂，而预测的过程则更加简单和优美。市面上存在着各种SVM的开源实现，而对于大部分的分类问题，SVM都可以得到比较好的分类效果，作为baseline，总是可以在各种paper中作为背景帝出现。

以前我对SVM的具体算法一直有畏惧的情绪。那是因为一次人工智能课的开卷考试，居然出了一道问答题让我回答什么是支持向量机（这里不得不黑一下母校当年的出卷老师，这里就不点名了）。我当时一个学期没怎么上过课，考前也没有看过书，对于SVM一无所知，只记得当时抄了整整一面卷子的公式，只觉天昏地暗。从此，心理就对SVM就产生了一种畏惧的情绪。直到若干年以后，我才慢慢领悟到，原来SVM并没有这么难，其实是可以用很简单的话就能够说清楚的。然而，后来我发现我又错了，但这是后话了。这里，我尝试先抛开各种繁琐的公式与理论，简单的说说我的SVM的直观理解。

<!--more-->

机器学习中的分类问题，看起来其实并不是太复杂。最直接的做法，是把已经标好的正负样本点都放在它们所在的线性空间进行观察。需要学习的分类函数则是这个空间里的一个平面或者曲面，能够很好地把训练集中的正负样本分隔开来，当然，更重要的是，还需要对训练数据以外的数据同样起作用。为了描述简单，我们就假设所有的样本都是二维空间中的一个点，而针对这样样本的线性分类器，则是在平面上的一条直线。

下面的图展示了一个成功的线性分类器，它成功地分隔了训练数据集中的正样本和负样本（分别对应图中的原点和方点）。这个场景就像刚刚摆好棋子的象棋盘，双方棋子各在楚河汉界一边，泾渭分明。当然，这样的情况往往只在理想中，很少出现在现实世界，否则，我们也不用去花这么多的力气研究各种各样的分类算法了。不过，这样一个简单的例子，可以作为我们学习SVM的一个开始。
![svm示意图]({{ site.img_url }}/svm/svm1.svg)

前面给出了分类器的直观几何解释，下面来用代数的语言简单的对这个分类的问题进行一下描述。对于上面空间中的每一个点，可以用一个向量\\( x_i\\)来表示。最后分类的结果，可以用\\( (+1,-1)\\)表示，分别对应正样本和负样本。而我们学习的分类器则可以看成是一个这样的函数\\(f\\)，它的输入是\\(x\\)，输入\\( f(x)\\)则是\\(+1\\)或\\(-1\\)中的某一个值。

