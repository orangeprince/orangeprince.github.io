---
layout: post
title: "闲话SVM(一)"
category: "技术"
tags: [机器学习,SVM]
---

SVM，全称Support Vector Machines，中文叫做支持向量机，是最常用的机器学习算法之一。SVM的出现对机器学习的理论发展具有里程碑式的意义。而与此同时，SVM又是一个非常接地气的算法，模型的训练过程并不算复杂，而预测的过程则更加简单和优美。市面上存在着各种SVM的开源实现，而对于大部分的分类问题，SVM都可以得到比较好的分类效果，作为baseline，总是可以在各种paper中作为背景出现。

以前我对SVM的具体算法一直有畏惧的情绪。那是因为一次人工智能课的开卷考试，居然出了一道问答题让我回答什么是支持向量机（这里不得不黑一下母校当年的出卷老师，这里就不点名了）。我当时一个学期没怎么上过课，考前也没有看过书，对于SVM一无所知，只记得当时抄了整整一面卷子的公式，只觉天昏地暗。从此，心理就对SVM就产生了一种畏惧的情绪。直到若干年以后，我才慢慢领悟到，原来SVM并没有这么难，其实是可以用很简单的话就能够说清楚的。然而，后来我发现我又错了，但这是后话了。这里，我尝试先抛开各种繁琐的公式与理论，用最直观的方式道出SVM最朴素的motivation。

<!--more-->

机器学习中的分类问题，看起来其实并不是太复杂。最直接的做法，是把已经标好的正负样本点都放在它们所在的线性空间进行观察。需要学习的分类函数则是这个空间里的一个平面或者曲面，能够很好地把训练集中的正负样本分隔开来，当然，更重要的是，还需要对训练数据以外的数据同样起作用。为了描述简单，我们就假设所有的样本都是二维空间中的一个点，而针对这样样本的线性分类器，则是在平面上的一条直线。

下面的图展示了一个成功的线性分类器（至少对于训练样本来说是这样）。这个分类器成功地分隔了训练数据集中的正样本和负样本（分别对应图中的原点和方点）。
![svm示意图]({{ site.img_url }}/svm/svm1.png)

我们能够用手在图上画出各种直线来分隔正负样本点，可我们终归需要