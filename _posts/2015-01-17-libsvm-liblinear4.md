---
layout: post-no-feature
title: "LIBSVM与LIBLINEAR（四）"
category: tech
tags: [MachineLearning]
---


## 特征的预处理

一般而言，利用LIBSVM和LIBLINEAR训练分类器之前，会对数据的特征进行预处理。预处理有两类，一类是针对特征内在逻辑的处理，比如增加一些dummy变量，或者对特征的范围进行一些认为的调整。这样的特征构造和处理对于分类器的效果也有着非常重要的影响，尤其是线性分类器，由于本身判别能力偏弱，所以更依赖于人工的特征构造。当然，这一类的特征与处理往往与数据本身的理解有很大的关系，不同的业务与应用场景处理的方法网玩那个也不同，这里就不做过多讨论了。

另一类特征的预处理则更加通用，即统一特征的尺度。由于特征的采集方式不同，造成数据原始特征在不同维度往往会有较大的差别。比如对一个人的身体指标进行描述，身高如果单位是米的话，每个人的值都在1到2之间。而体重以千克为单位，每个人至少应该是两位数，或者三位数。如果直接使用这样的原始特征进行分类，一方面某些特征的权重会被人为加大，影响模型的准确性。另外一方面，由于某些维度的scale过大，也会造成优化中的一些效率问题，增加迭代收敛的次数。因此，在进行分类前，一般需要对特征进行归一化，将特征调成到统一尺度。

最常见的归一化方法就是针对特征的每一个维度进行归一化，使得不同的度量在尺度上达到统一。一般来说，scale后特征的值都落在区间[-1,+1]或[0,1]之间。在实际使用时，更加倾向于后者，因为特征稀疏后往往能够提高优化的效率。LIBSVM提供了svm-scale程序进行特征的自动归一化，以归一化到[0,1]为例，主要是根据公式：

$$
\large
\begin{align}
x' = (x-x_{min})/(x_{max} - x_{min})
\end{align}
$$

此外，还有一些地方需要特别注意：第一，训练数据和测试数据必须采用统一的归一化函数，保证数据的一致性，既$x_{max}$和$x_{min}$必须是一致的。第二，并不是所有场景都是用于按特征的归一化。比如文本分类的场景中，通常会对每一个instance进行归一化，或者采用一些更加复杂的归一化算法。

## 其他问题

除了以上列出的一些关键问题，还有很多琐碎的小点也值得注意，如分类结果的评估方法、不同语言的调用接口、结果的可视化等等，限于篇幅，这里就不详细介绍了。感兴趣的读者可以参考相关资料。

## 其他的工具	

除LIBSVM和LIBLINEAR之外，还有一些工具包也能完成类似的功能，下面做一个简单地介绍。

* SVMLight。与LIBSVM起名的工具包，但是我个人用的不多。数据的格式与LIBSVM相当，但是据说使用更少的资源。此外，SVMLight的扩展还支持排序学习与结构化SVM的训练，因此也有着大量的使用者。
* SVMLin。专为线性SVM训练开发的工具包，之前有过介绍，另外还支持半监督SVM的训练。
* LIBLINEAR SPARK版本。最近LIBLINEAR提供了Spark版本，保留了Liblinear的一些基本功能，能够处理更大规模的数据。

